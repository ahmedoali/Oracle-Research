---
title: "Oracle validation report"
author: "Ahmed Ali"
date: "13 November 2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

This report will be taking a look into how an oracle can validate cryptocurrency prices only using data provided to it by feed providers. This report will not be delving into technical information around oracles but will present simulations and data analysis to inform on what indicators/algorithm an oracle can utilise to arrive at the "real" price at x time point. This is purely a data perspective on how to pick the best price.


## A discussion on measures

Since the Oracle can only act on what it recieves, it must assume that the real price is amongst the data provided. This will require the system to assess the inputs and choose a value possibly using some sort of data aggregation method. This presents a number of issues such as; what if malicious providers input wrong data on purpose, what about the price differences the cryptocurrency is trading at and which measure is best for performing such a task. 

There are many ideas which can be explored as a solution. A solution would also have to take into consideration the behaviours of the area the data originates from. Using previous data as prior information would be useful in making sure there isn't any serious discrepencies between each aggregated data point but would be tricky due to the volatility commonly associated with cryptocurrencies. Another idea is analysing the common patterns of price distributions across exchanges and other feed providers to help inform the oracle with a set of tests it can use to critique the inputs. One other possible solution is weighting - this would help incentivise good data if done properly but if weights are calculated relative to other inputs at the same time point, this could prove to encourage the wrong incentive if the system can be gamed by malicious providers working together to input similar wrong data which would give them higher weights over low weights for good data.

In general the median should be sufficient as a robust measure to extract the "correct" price and the median absolute deviance would help in analysing what the median deviation of exchanges from the median is. As the research in the following sections will show - both measures are pretty robust even when poor quality feed or malicious providers start sneaking in but remain a minority. This will be shown by an experiment where poor quality data is simulated and added into random feeds by random exchanges which will help in understanding the point at which the oracle should shut down or hand out large penalties. 

## Economic incentives & Simulations
A feed provider will need to be incentivised to provide good data and disincentivised to consider malpractice. Since decentralisation is the goal, deposits should not be too large which may discourage potential feed providers but also not too small which may possibly contribute to low quality feed. The deposit should demonstrate to individuals involved with a smart contract that the feed provider has enough to be punished in case they provide bad data. Hence the minimum deposit $d$ formula may have a relationship with parameters such as; total fees $f$ from smart contracts interested in the data at time point x, a penalty $p$ for malicious inputs and the total value $v$ circulating each day in the financial ecoystem.

The penalties and rewards can be linked with a weighting system to the feed provider's proximity to the median.
An implementation in R of a simple simulation of such an idea can be seen below:


```{r}
set.seed(123)
N <- 5 # Number of inputs for each exchange
N_feeds <- 10 # Number of feed providers, can simulate random number of feeds if needed
deposits <- runif(N_feeds,1000,30000) # Simulating initial deposits for each feed provider
results <- list() # Final results will be stored in a list
for(j in 1:N){
  
  # New inputs
  feed_input <- runif(n = N_feeds, min = 1000, max = 1500)
  
  # Initial deposit
  Initial_deposit <- deposits
  
  # Weighting
  med <- median(feed_input)
  med_abd <- mad(feed_input)
  weight <- (med - feed_input)^2
  weight_scaled <- 1 - (weight - min(weight))/(max(weight) - min(weight))
  
  for(i in 1:N_feeds){
    TVL <- sum(deposits)
    min_deposit <- 0.05*TVL
  
  # Punish low deposits
  if(deposits[i] < min_deposit){
    deposits[i] = deposits[i] - log(TVL)
  }
  
  # Penalty
  Penalty <- (1-weight_scaled)*0.01*deposits
  
  # Reward
  Reward <- weight_scaled*0.1*deposits
  
  # Adjust deposit
  deposits[i] <- deposits[i] + Reward[i] - Penalty[i]
  
  # Names 
  Names <- paste0("Provider"," ",seq(1,N_feeds,1))
  
  }
  # Store results
  results[[j]] <- data.frame("Providers" = Names,"Feed input" = feed_input, "Median input" = rep(med,N_feeds)
                             ,"MAD" = rep(med_abd,N_feeds)
                             ,"Min Deposit" = rep(min_deposit,N_feeds), "Initial_deposit" = Initial_deposit
                             ,"Final Deposit"= deposits
                             ,"Weight"=weight_scaled,"Reward" = Reward,"Penalty" = Penalty)
}
library(knitr)
kable(results[[1]], caption = "First iteration")
```


At the first iteration we can see that each provider is assigned a weight depending on how far they are from median and each feed provider is assessed relative to what other feed providers submitted. Weights are calculated by squaring the difference between the inputs and the median and then scaling using the min-max scaling method. This can improved by scaling weights within 0.4 to 1 for instance and assigning weights of 0 to feed providers with malicious inputs. Currently a small penalty was given to feed provider 9 despite obtaining a very high weight - however their reward is the third highest and will offset the miniscule penalty. One further improvement that will be needed here will be the introduction of smart contract fees will be distributed amongst the feed providers rather than their reward being linked to their deposit.

This is one method which can help in incentivising good data, disincentivising bad data and provide feed providers with a fair reward. However in such a system, suppose we obtain data which is extremely well behaved, a good provider may be punished simply because other good providers obtained data close to the median. This can be solved simply by not allowing the weights to be used in deciding rewards and penalties but instead using a set of tests which will be able to identify malicious feed providers. The weights calculated however do indicate good performers and bad performers relative to each other so its useage can be alongside a set of tests rather than being its own condition.






